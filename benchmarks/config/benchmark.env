# Benchmark Configuration
# Based on methodology from:
# https://gitlab.com/postgres-ai/postgresql-consulting/tests-and-benchmarks/-/issues/63

# Database settings
PGUSER=postgres
PGPASSWORD=postgres
PGDATABASE=postgres

# Target endpoints
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

PGBOUNCER_HOST=localhost
PGBOUNCER_PORT=6432

MULTIGRES_HOST=localhost
MULTIGRES_PORT=15432

# Optional: PgDog endpoint (uncomment to enable)
# PGDOG_HOST=localhost
# PGDOG_PORT=6433

# Optional: SPQR endpoint (uncomment to enable)
# SPQR_HOST=localhost
# SPQR_PORT=6435

# Optional: Citus endpoint (uncomment to enable)
# CITUS_HOST=localhost
# CITUS_PORT=6434

# pgbench parameters (from issue #63 methodology)
PGBENCH_SCALE=1           # Scale factor (1 = small dataset, measures proxy overhead)
PGBENCH_TIME=300          # Duration per test in seconds (5 minutes for stable results)
PGBENCH_JOBS=4            # Number of worker threads
PGBENCH_THREADS=4         # Number of client threads
PGBENCH_PROGRESS=30       # Report progress every N seconds
WARMUP_TIME=0             # Warmup handled by initial pgbench run

# Client counts to test
# Issue #63 uses 4 clients for latency overhead measurement
PGBENCH_CLIENTS="4"

# For scaling tests, uncomment:
# PGBENCH_CLIENTS="4 10 50 100"

# Test types to run
# readonly: SELECT-only workload with extended protocol (primary test from issue #63)
# default: pgbench TPC-B like workload
# simple: SELECT 1 (pure overhead test)
TEST_TYPES="readonly"

# For comprehensive testing, use:
# TEST_TYPES="readonly default simple"

# Protocol mode
# extended: Use extended query protocol (recommended, matches issue #63)
# simple: Use simple query protocol
PGBENCH_PROTOCOL=extended

# Systems to benchmark
TARGETS="postgres pgbouncer multigres"

# Results directory
RESULTS_DIR=./results

# Repeat each test N times for statistical significance
REPEATS=1

# For more reliable results, use:
# REPEATS=3
